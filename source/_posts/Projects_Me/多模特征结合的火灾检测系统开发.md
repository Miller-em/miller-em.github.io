---
title: 多模特征结合的火灾检测系统开发
date: 
tags: ['深度学习', '项目']
categories: 项目
top: false
---

## 项目背景



最近，基于前段时间西昌的森林发生火灾，不仅对当地的居民，环境和森林动物都造成了极大的影响，还对我国人力和物力造成损失。我们团队思考着能不能用到一些智能化的手段，能够在火势刚刚兴起的时候，能够检测并且通过互联网(或者其他的手段)实现预警。对于市场目前的调研来说，目前都是使用烟雾报警器，或者红外技术监测。但是目前深度学习技术驱动下的计算机视觉快速发展，我们就不能考虑到能够通过摄像头实现火灾，烟雾的检测？基于此，想到了利用目标检测来解决火焰检测的问题。通过烟雾传感器，红外传感设备的辅助作用下，实现这么一个森林火灾预警系统的设计。

<!-- more -->



## 设计框图

![image-20210716120632813](https://cdn.jsdelivr.net/gh/Miller-em/IMAGS/img/20210716120633.png)

## 整理数据集和训练模型

首先，要先搜集好数据集，这个项目中要应用的数据集是火灾相关的数据图片，感谢社区朋友的开源支持，我拿到了1w未标注和2千张已标注的数据集，已标注的数据集只实现了火的分类，我认为太少了，就找团队的朋友帮我标了三千张，分类是：fire，smoke，person。下面介绍细节：

### 1.整理数据集

我们将3000张图片整理成了coco数据集类型，我将标注好的数据集分成以下目录结构：

```
----fire_detect
 |---images
   |---train
   |---test
 |---labels
   |---train
   |---test
```

train和test目录下放的就是训练集2400张和测试集600张。整理好了上传给服务器。

### 2.训练模型

首先，把yolov5从仓库git下来：

```
git clone https://github.com/ultralytics/yolov5.git
cd yolov5
cd data
```

然后建立一个`fire_det.yaml`

![image-20210715095029642](https://cdn.jsdelivr.net/gh/Miller-em/IMAGS/img/20210715095029.png)

准备工作就已经做好了，运行以下目录训练：

```
cd .. //将目录路径改在yolov5下面
python3 train.py --img 640 --batch 16 --epochs 300 --data fire_det.yaml --weights yolov5s.pt  //训练
python3 detect.py --source ../fire_dataset/fire_detect.mp4 --weights runs/train/exp__/weights/best.pt --conf 0.25  //测试模型

```



## 将模型部署到Jetson

我们要启用Jetson Nano上面的的tensorrt进行加速，需要得到能够供tensorrt推理的模型文件（.engine）。然后我们使用的是**.pt -> .wts -> .engine**的路线来生成，下面将记录一下过程：

### 1.利用.pt生成.wts文件

```
git clone -b v5.0 https://github.com/ultralytics/yolov5.git
git clone https://github.com/wang-xinyu/tensorrtx.git
cp {tensorrtx}/yolov5/gen_wts.py {ultralytics}/yolov5
cd {ultralytics}/yolov5
python gen_wts.py yolov5s.pt
```

### 2.编译和运行./yolov5

```
cd {tensorrtx}/yolov5/
// 对于自定义的数据集，需要修改yololayer.h里面的CLASS_NUM
mkdir build
cd build
cp {ultralytics}/yolov5/yolov5s.wts {tensorrtx}/yolov5/build
cmake ..
make
sudo ./yolov5 -s [.wts] [.engine] [s/m/l/x/s6/m6/l6/x6 or c/c6 gd gw]  // serialize model to plan file
```

### 3.修改yolov5_trt.py

 这个主要是对文件中的调用引擎文件的路径做修改，其他的修改我已经修改好了，所以后面对于模型更换后，只需要更改模型引擎路径就好了。修改好的yolov5_trt.py，我已经放到了到github，随时可以git下来使用。

![image-20210715094242836](https://cdn.jsdelivr.net/gh/Miller-em/IMAGS/img/20210715094304.png)

### 4.最终效果

![image-20210715100402754](https://cdn.jsdelivr.net/gh/Miller-em/IMAGS/img/20210715100403.png)

![image-20210715100416360](https://cdn.jsdelivr.net/gh/Miller-em/IMAGS/img/20210715100416.png)

![image-20210715100447503](https://cdn.jsdelivr.net/gh/Miller-em/IMAGS/img/20210715100447.png)

这个本来是能够在13fps左右完成检测，但是我打开了浏览器，降低了检测性能，只能够到10fps左右。但是对于yolov5来说，这已经是个较为满意的结果了，模型训练的工作就到此为止了，以后可能会用到其他高效的检测模型，比如nanonet等轻量化模型。